{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark \n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Wine Quality Prediction\").enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('TrainingDataset.csv',header='true', inferSchema='true', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_name_list= list(map(lambda x: x.replace(\"\\\"\\\"\", \"\"), df.columns))\n",
    "\n",
    "df = df.toDF(*new_column_name_list)\n",
    "\n",
    "df = df.withColumnRenamed(\"quality\\\"\", \"quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isTasty(quality):\n",
    "    if quality >= 7:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "tasty_udf_int = udf(isTasty, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tasty = df.withColumn(\"tasty\", tasty_udf_int('quality'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureColumns = [\"alcohol\", \"volatile acidity\", \"sulphates\", \"citric acid\", \"total sulfur dioxide\", \"density\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACKING_URI = 'http://<user_name>:<password>@<ec2_public_address>/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=featureColumns, \n",
    "                            outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = assembler.transform(df_tasty).select('features', 'tasty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = spark.read.csv('ValidationDataset.csv',header='true', inferSchema='true', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_name_list= list(map(lambda x: x.replace(\"\\\"\\\"\", \"\"), df.columns))\n",
    "\n",
    "df_test = df_test.toDF(*new_column_name_list)\n",
    "\n",
    "df_test = df_test.withColumnRenamed(\"quality\\\"\", \"quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_tasty = df_test.withColumn(\"tasty\", tasty_udf_int('quality'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureColumns_test = [\"alcohol\", \"volatile acidity\", \"sulphates\", \"citric acid\", \"total sulfur dioxide\", \"density\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler_test = VectorAssembler(inputCols=featureColumns_test, \n",
    "                            outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = assembler_test.transform(df_test_tasty).select('features', 'tasty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'tasty', maxIter=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel = lr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lrModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f-score on test data = 0.870752\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "lr_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol='tasty', predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = lr_evaluator.evaluate(predictions)\n",
    "print(\"f-score on test data = %g\" % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
